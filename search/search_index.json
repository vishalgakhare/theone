{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Vishal Gakhare's CV","text":"<ul> <li>Email: vishalgakhare@outlook.com</li> <li>Location: Richmond, USA</li> <li>Website: vishalgakhare.github.iotheone</li> <li>LinkedIn: vishalgakhare</li> <li>GitHub: vishalgakhare</li> </ul>"},{"location":"#summary","title":"Summary","text":"<p>Experienced Software Engineer with a strong background in AWS cloud solutions, system architecture, and application optimization. Proven track record in leading development teams and initiatives to enhance software performance and reliability. Adept at leveraging programming skills in NodeJS, Python, and Java to solve complex problems and improve business operations through technology.</p>"},{"location":"#skills","title":"Skills","text":"<ul> <li>Areas of Expertise: Cloud Computing Solutions, Design and Development, System Architecture.</li> <li>Languages: NodeJS/TS, Python, Java, C#, SQL</li> <li>Tools: VS Code, Shell</li> <li>Databases: MongoDB, PostgreSQL, Oracle</li> <li>Domains: Banking, Securities, Telecom</li> </ul>"},{"location":"#certifications","title":"Certifications","text":"<ul> <li>AWS Certified Developer: Expired Oct 2024</li> <li>AWS Certified Solutions Architect: Expires July 2025</li> </ul>"},{"location":"#experience","title":"Experience","text":""},{"location":"#capital-one-sr-lead-software-engineer","title":"Capital One, Sr Lead Software Engineer","text":"<ul> <li>May 2022 \u2013 present</li> <li>Richmond, VA</li> <li>2024 - Led initiative to execute Build vs. Buy POC of AWS Contact Lens for its capabilities and performance, in partnership with Card Data Science and AWS.</li> <li>2023 - Led multiple well-managed and SRE initiatives. Prepared a strategy to elevate the Test Automation Level based on application patterns.</li> </ul>"},{"location":"#capital-one-lead-software-engineer","title":"Capital One, Lead Software Engineer","text":"<ul> <li>Oct 2012 \u2013 May 2022</li> <li>Richmond, VA</li> <li>2021-22 - Engineered 'VSS Lite' suite of Lambda apps in NodeJS/TS as a DR solution for IVR. Developed serverless apps and utilities for telephony integration with Amazon Lex. Re-designed and developed softphone application OneComm.</li> <li>2019-20 - Led the modernization of data processing jobs (Ab initio) to cloud-based solutions (PySpark ETL), enhancing efficiency and scalability.</li> <li>2018 - Worked on Java Spark and NodeJS batches to tokenize ~50M accounts and migrate ~250M records.</li> <li>2015 - Developed core services (logging, exception handling, file rollover) in C# for the Agent Servicing Platform (IRIS).</li> <li>2016 - Developed high-performance REST API services using NodeJS and MongoDB, handling 2 million daily requests with exceptional reliability and speed.</li> <li>2014 - Delivered high quality CTI solution in C# via agile best practices such as Paired Programming, TDD. Elevated &amp; maintained code quality and PCI compliance by identifying &amp; disseminating the solutions to the IRIS platform teams.</li> <li>2012 - Worked on CTIBHO (Computer Telephony Interface) to support Avaya Dialer upgrade to version 5. The project won the Enterprise Circle of Excellence award</li> </ul>"},{"location":"#wells-fargo-via-infosys-technology-analyst","title":"Wells Fargo (via Infosys), Technology Analyst","text":"<ul> <li>Dec 2009 \u2013 Oct 2012</li> <li>Richmond, VA</li> <li>Worked on a project of Wells Fargo &amp; Wachovia merger to optimize and fine-tune application performance and Oracle DB queries. Achieved a remarkable 50% improvement in Oracle DB performance and an impressive 90% enhancement in application loading speed.</li> <li>Acted as the vital link between the offshore development team and onsite client/business analysts, ensuring seamless communication and coordination for project success.</li> </ul>"},{"location":"#wells-fargo-via-infosys-senior-software-engineer","title":"Wells Fargo (via Infosys), Senior Software Engineer","text":"<ul> <li>May 2007 \u2013 Oct 2009</li> <li>Hyderabad, India</li> <li>Programmed robust client-server web applications, Windows Services, and Web Services using C#.NET driving enhanced performance and reliability across platforms.</li> </ul>"},{"location":"#verizon-via-infosys-software-engineer","title":"Verizon (via Infosys), Software Engineer","text":"<ul> <li>Dec 2005 \u2013 May 2007</li> <li>Mysore, India</li> <li>Spearheaded the development of a Verizon One Source module in C#.NET through all waterfall phases, single-handedly delivering a flawless solution with zero bugs.</li> </ul>"},{"location":"#education","title":"Education","text":""},{"location":"#government-college-of-engineering-amravati-university-india-be-in-information-technology","title":"Government College of Engineering, Amravati University, India, BE in Information Technology","text":"<ul> <li>Sept 2001 \u2013 May 2005</li> <li>Percentage Score: 65%</li> <li>Coursework: Computer Architecture, OS, Data Structures &amp; Algorithms, DBMS, Networking, Software Engineering, Digital Communication</li> </ul>"},{"location":"Physics/","title":"Physics","text":"<ul> <li>https://explorabl.es/physics/</li> </ul>"},{"location":"AWS/Cheatsheet/","title":"Cheatsheet","text":""},{"location":"AWS/Cheatsheet/#ec2","title":"EC2","text":"<ul> <li>Dedicated (Instances): No other customers will share the hardware. May share hardware with other instances of ONLY your account.</li> <li>(Dedicated) Hosts: Book an entire physical server and have full control of EC2 instance placement.</li> <li>You can only change the tenancy of an instance from dedicated to host or from host to dedicated after you\u2019ve launched it.</li> <li>Good EC2 combo -&gt; reserved instances for baseline + on-demand &amp; spot for peaks.</li> </ul> <p>Userdata</p> <ul> <li>Executed as root by default.</li> </ul> <p>Hibernate</p> <ul> <li>Hibernation saves the contents from the instance memory (RAM) to your Amazon EBS root volume. When you start your instance: The Amazon EBS root volume is restored to its previous state. The RAM contents are reloaded.</li> </ul> <p></p> <p>EC2 Hibernation</p> <ul> <li>To use hibernation, the root volume must be an encrypted EBS volume.</li> <li>When the instance state is stopping, you will not be billed if it is preparing to stop. However, you will still be billed if it is just preparing to hibernate.</li> </ul> <p>Spot instances</p> <ul> <li>A Spot Instance request is either one-time or persistent. If the spot request is persistent, the request is opened again after your Spot Instance is interrupted.</li> <li>Spot blocks are Spot Instances with a defined duration &amp; are designed not to be interrupted.</li> <li>If your Spot Instance request is disabled and has an associated stopped Spot Instance, canceling the request does not terminate the instance.</li> </ul>"},{"location":"AWS/Cheatsheet/#placement-groups","title":"Placement groups","text":"<ul> <li>It is recommended that you launch the number of instances that you need in the placement group in a single launch request and that you use the same instance type for all instances in the placement group. If you try to add more instances to the placement group later, or if you try to launch more than one instance type in the placement group, you increase your chances of getting an insufficient capacity error.</li> <li>If you receive a capacity error when launching an instance in a placement group that already has running instances, stop and start all of the instances in the placement group and try the launch again. Restarting the instances may migrate them to hardware that has the capacity for all the requested instances.</li> </ul> <p>Spread</p> <ul> <li>Maximum of 7 running instances per Availability Zone per group.</li> <li>Recommended for applications that have a small number of critical instances that should be kept separate from each other.</li> <li>Spread placement groups provide access to distinct racks and are therefore suitable for mixing instance types or launching instances over time.</li> </ul> <p>Cluster</p> <ul> <li>Higher per-flow throughput limit of up to 10 Gbps for TCP/IP traffic and are placed in the same high-bisection bandwidth segment of the network.</li> </ul> <p>Partition</p> <ul> <li>Spreads your instances across logical partitions such that groups of instances in one partition do not share the underlying hardware with groups of instances in different partitions.</li> <li>Used by large distributed and replicated workloads.</li> </ul>"},{"location":"AWS/Cheatsheet/#autoscaling","title":"Autoscaling","text":"<ul> <li>Lifecycle hooks enable you to perform custom actions as the Auto Scaling group launches or terminates instances.</li> </ul> <p>EC2 Autoscaling Lifecycle Hooks</p> <ul> <li>Lifecycle hooks put the instance into a wait state until the script or timeout period ends.</li> <li>With launch templates, you can provision capacity across multiple instance types using both On-Demand Instances and Spot Instances.</li> <li>You can put an instance that is in the InService state into the Standby state, update some software or troubleshoot the instance, and then return the instance to service.</li> <li>Auto Scaling doesn\u2019t terminate an instance that came into service based on EC2 status checks and ELB health checks until the health check grace period expires.</li> <li>Cooldown period: It ensures that the Auto Scaling group does not launch or terminate additional EC2 instances before the previous scaling activity takes effect(default 300s).</li> <li>Amazon EC2 Auto Scaling does not immediately terminate instances with an Impaired status.</li> <li>By default, Amazon EC2 Auto Scaling doesn\u2019t use the results of ELB health checks to determine an instance\u2019s health status when the group\u2019s health check configuration is set to EC2.</li> <li>When there are multiple policies in force at the same time, Auto Scaling chooses the policy that provides the largest capacity for both scale-out and scale-in.</li> <li>The default value for the instance placement tenancy is null, and the instance tenancy is controlled by the tenancy attribute of the VPC. If you set the Launch Configuration Tenancy to default and the VPC Tenancy is set to dedicate, then the instances have dedicated tenancy. If you set the Launch Configuration Tenancy to dedicated and the VPC Tenancy is set to default, then again, the instances have dedicated tenancy.</li> <li>If you have an EC2 Auto Scaling group (ASG) with running instances and you choose to delete the ASG, the instances will be terminated, and the ASG will be deleted.</li> <li>Rebalancing AZs launches new instances before terminating the old ones.</li> <li>Auto Scaling creates a new scaling activity for terminating the unhealthy instance and then terminates it. Later, another scaling activity launches a new instance to replace the terminated instance.</li> </ul>"},{"location":"AWS/Cheatsheet/#s3","title":"S3","text":"<ul> <li>S3 standard: There is no minimum storage duration charge and no retrieval fee (use case: if you want to keep data for a few days only)</li> <li>Object-level permissions: For actions inside the bucket(e.g. GetObject), add / after arn, -&gt; arn:aws:s3:::test/</li> <li>With bucket policies, you can grant users within your AWS Account or other AWS Accounts access to your Amazon S3 resources.</li> <li>The AWS S3 sync command uses the CopyObject APIs to copy objects between S3 buckets.</li> <li>By default, S3 replication only supports copying new Amazon S3 objects after it is enabled.</li> <li>Max upload 5GB per time, for more use multi-part upload. If the object to upload is &gt; 100 MB, you should consider using multipart uploads.</li> <li>Amazon S3 delivers strong read-after-write consistency automatically.</li> <li>You can increase your read or write performance by parallelizing reads with prefixes.</li> <li>Once you version-enable a bucket, it can never return to an unversioned state. Versioning can only be suspended once it has been enabled.</li> <li>No S3 data transfer charges when data is transferred in from the internet.</li> <li>Also, with S3TA, you pay only for transfers that are accelerated.</li> <li>Using the Range HTTP header in a GET Object request, you can fetch a byte range from an object, transferring only the specified portion. A byte-range request is a perfect way to get the beginning of a file.</li> <li>You can place a retention period on an object version. Different versions of a single object can have different retention modes and periods.</li> <li>Max object size 5TB.</li> <li>For replication must enable versioning in source and destination.</li> <li>By default, an S3 object is owned by the AWS account that uploaded it, even in a bucket in a different account. To get full access to the object, the object owner must explicitly grant the bucket owner access. You can create a bucket policy to require external users to grant bucket-owner-full-control when uploading objects so the bucket owner can have full access to the objects.</li> <li>Object lock: store objects as locked(only on versioned buckets).</li> <li>Metadata, which can be included with the object, is not encrypted while being stored on Amazon S3. Therefore, AWS recommends that customers not place sensitive information in Amazon S3 metadata.</li> <li>S3 event notification allows destinations: SQS standard, Lambda, SNS.</li> <li>Allowed names for S3 website endpoints: http://bucket-name.s3-website.Region.amazonaws.com &amp; http://bucket-name.s3-website-Region.amazonaws.com</li> <li>S3 Select scan a subset of an object by specifying a range of bytes to query based on the bucket\u2019s name and the object\u2019s key.</li> <li>With S3 Select, you can use simple structured query language (SQL) statements to filter the contents of an Amazon S3 object and retrieve just the subset of data that you need. CSV, JSON, or Apache Parquet format.</li> <li>S3 can publish notifications for the following events: New object-created events, Object removal events, Restore object events, Reduced Redundancy Storage (RRS) object lost events, Replication events.</li> <li>To encrypt an object at the time of upload, you need to add a header called x-amz-server-side-encryption. To enforce object encryption, create an S3 bucket policy that denies any S3 Put request that does not include the x-amz-server-side-encryption header.</li> <li>To enable S3 website: a) An S3 bucket that is configured to host a static website. The bucket must have the same name as your domain or subdomain, b) a registered domain name c) Route 53 as the DNS service for the domain.</li> <li>S3 server access logs provide detailed records for the requests that are made to an S3 bucket.</li> <li>3,500 requests per second to add data and 5,500 requests per second to retrieve data.</li> <li>You can have an S3 bucket that has different objects stored in S3 Standard, S3 Intelligent-Tiering, S3 Standard-IA, and S3 One Zone-IA.</li> </ul> <p>S3 IA</p> <ul> <li>S3 One Zone-IA is for data that is accessed less frequently but requires rapid access when needed.</li> <li>The minimum storage duration is 30 days before you can transition objects from S3 Standard to S3 Standard IA or One Zone-IA.(This limitation does not apply to Intelligent Tiering, Glacier, and Glacier Deep Archive)</li> </ul> <p>S3 Lifecycle Transitions</p> <p>Supported lifecycle transitions \u2014 waterfall model:</p> <ul> <li>The S3 Standard storage class to any other storage class.</li> <li>Any storage class to the S3 Glacier or S3 Glacier Deep Archive storage classes.</li> <li>The S3 Standard-IA storage class to the S3 Intelligent-Tiering or S3 One Zone-IA storage classes.</li> <li>The S3 Intelligent-Tiering storage class to the S3 One Zone-IA storage class.</li> <li>The S3 Glacier storage class to the S3 Glacier Deep Archive storage class.</li> </ul> <p></p> <p>S3 Lifecycle Transitions</p> <ul> <li>Encrypted objects remain encrypted throughout the storage class transition process.</li> </ul> <p>Glacier</p> <ul> <li>Glacier supports encryption by default for both data at rest as well as in transit.</li> <li>The minimal storage duration period is 90 days for the S3 Glacier storage class and 180 days for S3 Glacier Deep Archive.</li> <li>Data can be stored directly in Amazon S3 Glacier Deep Archive.</li> </ul> <p>Snowball</p> <ul> <li>Snowball Edge storage optimised: 80TB 40 vCPUs, 1 TB of SATA SSD storage, and up to 40 Gb network connectivity.</li> <li>You can\u2019t directly copy data from Snowball Edge devices into AWS Glacier.</li> <li>For data &lt; 10PB or distributed in multiple locations.</li> <li>Snowball Edge compute optimised(52 vCPUs, 42 TB of usable block or object storage, and an optional GPU).</li> <li>Snowball Edge possibility for storage clustering.</li> <li>AWS OpsHub is a graphical user interface you can use to manage your AWS Snowball devices.</li> </ul> <p>Snowmobile</p> <ul> <li>Each Snowmobile has a total capacity of up to 100 petabytes.</li> <li>For data &gt; 10PB in a single location.</li> </ul> <p></p> <p>Snow Services Comparison</p>"},{"location":"AWS/Cheatsheet/#iam","title":"IAM","text":"<ul> <li>Permissions Boundary to limit max access of users. They can only be applied to roles or users, not IAM groups.</li> </ul> <p>IAM Permissions Boundaries</p> <ul> <li>IAM Policy Evaluation Logic: if there is an explicit deny, the final decision is to deny for the resource.</li> <li>When you assume a role, you give up your original permissions and take the permissions of the assigned role.</li> <li>When using a resource-based policy, the principal doesn\u2019t have to give up his permissions.</li> <li>In a policy condition: aws:RequestedRegion represents the target of the API call.</li> <li>You can share an AMI with another account.</li> <li>Trust Policy: only IAM resource-based policy.</li> <li>If you got your certificate from a third-party CA, import the certificate into ACM or upload it to the IAM certificate store.</li> <li>With web identity federation, you don\u2019t need to create custom sign-in code or manage your own user identities. Instead, users of your app can sign in using a well-known external identity provider (IdP), such as Login with Amazon, Facebook, Google, or any other OpenID Connect (OIDC)-compatible IdP.</li> </ul> <p>Security Token Service(STS)</p> <ul> <li>Temporary security credentials that can control access to your AWS resources.</li> </ul> <p>AWS Organizations</p> <ul> <li>It does not offer the federation capability.</li> <li>To migrate an account to another Organization: remove member account, send an invite to new Org, Accept the invite to the new Org from the member account.</li> <li>SCPs offer central control over the maximum available permissions for all accounts in your organization, allowing you to ensure your accounts stay within your organization\u2019s access control guidelines.</li> <li>SCPs affect all users and roles in the attached accounts, including the root user.</li> <li>SCPs do not affect any service-linked role.</li> </ul>"},{"location":"AWS/Cheatsheet/#vpc","title":"VPC","text":"<ul> <li>VPN connection: Virtual Private Gateway endpoint on the AWS VPC side \u2014 Customer Gateway on the on-premises side.</li> <li>You can\u2019t have a VPC with only a public subnet and AWS Site-to-Site VPN.</li> <li>Private IPs allowed ranges: 10.0.0.0/8 (10.0.0.0\u201310.255.255.255), 172.16.0.0/12 (172.16.0.0\u2013172.31.255.255), 192.168.0.0/16(192.168.0.0\u2013192.168.255.255)</li> <li>AWS reserves 5 Ip addresses in each subnet.</li> <li>Shared services VPC, which provides access to services required by workloads in each of the VPCs. This might include directory services or VPC endpoints. Sharing resources from a central location instead of building them in each VPC may reduce administrative overhead and cost.</li> <li>Use AZ ID to uniquely identify the Availability Zones across the two AWS Accounts.</li> <li>By default, non-default subnets have the IPv4 public addressing(assign public IP) attribute set to false, and default subnets have this attribute set to true.</li> <li>You cannot disable IPv4 support for your VPC and subnets since this is the default IP addressing system for Amazon VPC and Amazon EC2.</li> <li>Every subnet that you create is automatically associated with the main route table for the VPC.</li> <li>Allowed block size in VPC is between a /16 netmask (65,536 IP addresses) and /28 netmask.</li> <li>While primary ENIs cannot be detached from an instance, secondary ENIs can be detached and attached to a different instance.</li> </ul> <p>Security Groups</p> <ul> <li>If nothing is defined in a security group, then all access is blocked.</li> </ul> <p>NACL</p> <ul> <li>NACLs are stateless, so outbound rules have to be evaluated again.</li> <li>Defined at Subnet level.</li> <li>Should allow outbound traffic from ephemeral ports.</li> <li>NACL rules are evaluated starting with the lowest numbered rule. As soon as a rule matches traffic, it\u2019s applied immediately regardless of any higher-numbered rule that may contradict it.</li> </ul> <p>Cloudhub</p> <ul> <li>Multiple AWS Site-to-Site VPN connections, you can provide secure communication between sites using the AWS VPN CloudHub, including Direct Connect connections.</li> <li>Supports IP Multicast.</li> <li>Low-cost primary or secondary network connectivity between locations, only for VPNs.</li> </ul> <p>Direct Connect</p> <ul> <li>Maximum resilience is achieved by separate connections terminating on separate devices in more than one location.</li> </ul> <p></p> <p>Direct Connect High Resiliency Setup</p> <ul> <li>Dedicated connection 1\u201310 Gbps.</li> <li>Hosted connection 50Mbps -10Gbps, add or remove capacity on demand.</li> <li>Data in transit is not encrypted, but private.</li> </ul> <p>Transit Gateway</p> <ul> <li>Network transit hub that you can use to interconnect your virtual private clouds (VPC) and on-premises networks.</li> <li>AWS Transit Gateway also enables you to scale the IPsec VPN throughput with equal-cost multi-path (ECMP) routing support over multiple VPN tunnels.</li> </ul> <p>NAT Instance</p> <ul> <li>It can be used as a bastion, supports security groups, supports port-forwarding, must disable ec2 flag source/destination check.</li> </ul> <p>Nat Gateway</p> <ul> <li>Only for IPv4.</li> <li>Set up in a public subnet.</li> <li>In a specific AZ, and can only be used by instances in other subnets.</li> </ul> <p>Egress-only Internet Gateway:</p> <ul> <li>nat for ipv6.</li> </ul>"},{"location":"AWS/Cheatsheet/#route53","title":"Route53","text":"<ul> <li>Routing policy multi-value supports up to 8 healthy records for each multi-value query.</li> <li>To integrate an external domain to route53, update the nameservers on the 3rd party registrar with your public hosted zone.</li> <li>To resolve any DNS queries for resources in the AWS VPC from the on-premises network, you can create an inbound endpoint on Route 53 Resolver, and then DNS resolvers on the on-premises network can forward DNS queries to Route 53 Resolver via this endpoint.</li> <li>To resolve DNS queries for any resources in the on-premises network from the AWS VPC, you can create an outbound endpoint on Route 53 Resolver, and then Route 53 Resolver can conditionally forward queries to resolvers on the on-premises network via this endpoint.</li> <li>Cannot create a CNAME record for the top node of the DNS namespace. So, if you register the DNS name mpla.com the zone apex is mpla.com. You can\u2019t create a CNAME record for mpla.com, but you can create an alias record for mpla.com that routes traffic to www.mpla.com.</li> <li>Route 53 doesn\u2019t charge for alias queries to AWS resources, but Route 53 does charge for CNAME queries.</li> <li>For each VPC that you want to associate with the Route 53 hosted zone, change the following VPC settings to true: enableDnsHostnames, enableDnsSupport.</li> <li>You configure active-active failover using any routing policy (or combination of routing policies) other than failover, and you configure active-passive failover using the failover routing policy.</li> <li> <p>Active-Active Failover when you want all of your resources to be available the majority of the time.</p> </li> <li> <p>Active-Passive Failover when you want a primary resource or group of resources to be available the majority of the time, and you want a secondary resource or group of resources to be on standby in case all the primary resources become unavailable.</p> </li> </ul>"},{"location":"AWS/Cheatsheet/#ebs","title":"EBS","text":"<ul> <li>By default, the root volume for an AMI backed by Amazon EBS is deleted when the instance terminates.</li> <li>For an encrypted EBS volume, data stored at rest on the volume, data moving between the volume and the instance, snapshots created from the volume, and volumes created from those snapshots are all encrypted.</li> <li>GP2: system boot volumes, 1GB \u2014 16TB, max IOPS 16,000; if you add 1TB, you get +3000IOPS for low latency interactive apps.</li> <li>io1/io2: 4GB-16TB, max 64,000 IOPS, 50:1 IOPS:GB ratio.</li> <li>io2 Block Express volumes, Provisioned IOPS (PIOPS) up to 256,000, with an IOPS:GiB ratio of 1,000:1, for submillisecond latency for &gt; 64,000 IOPS or 1000 MB/s throughput.</li> <li>Throughput optimised HDD(st1): max throughput 500 MB/s \u2014 max 500 IOPS \u2014 Big data, log processing, data warehouses.</li> <li>Cold HDD(scl): max throughput 250 MB/s \u2014 max 250 IOPS \u2014 Throughput-oriented storage that is infrequently accessed, low storage cost scenarios.</li> <li>Amazon EBS Multi-Attach enables you to attach a single Provisioned IOPS SSD (io1 or io2) volume to multiple instances with Nitro system that are in the same Availability Zone.</li> <li>Throughput Optimized HDD (st1) and Cold HDD (sc1) volume types cannot be used for boot volumes.</li> </ul> <p>EBS Types Comparison</p> <ul> <li>Locked to AZ, to attach to other AZ, you have to snapshot it.</li> <li>Copying an unencrypted snapshot allows encryption.</li> <li>When copying an AMI to another region, it automatically creates the underlying EBS snapshot also in the new region.</li> <li>RAID 0 to increase performance.</li> <li>RAID 1 to increase fault tolerance.</li> <li>If the instance is already running, you can set DeleteOnTermination to False using the command line for the root EBS volume.</li> <li>An in-progress snapshot is not affected by ongoing reads and writes to the volume; hence, you can still use the EBS volume normally.</li> <li>Enforce the encryption of the new EBS volumes and snapshot copies that you create with the Encryption by Default feature(no effect on existing EBS volumes or snapshots). If you enable it for a Region, you cannot disable it for individual volumes or snapshots in that Region.</li> <li>When you enable encryption by default, you can launch an instance only if the instance type supports EBS encryption.</li> <li>Amazon EBS does not support asymmetric CMKs.</li> </ul> <p>Instance Store</p> <ul> <li>Temporary block-level storage for your instance.</li> <li>Ideal for the temporary storage of information that frequently changes, such as buffers, caches, scratch data, and other temporary content, or for data that is replicated across a fleet of instances, such as a load-balanced pool of web servers</li> </ul> <p></p> <p>Instance Store</p> <ul> <li>For high I/O performance, instance store volumes are a better option.</li> <li>You cant resize the instance store.</li> </ul>"},{"location":"AWS/Cheatsheet/#efs","title":"EFS","text":"<ul> <li>Control which EC2 instances can access your EFS file system with security group rules and IAM policies.</li> <li>1000s on concurrent NFS clients, 10Gbs throughput.</li> <li>Use EFS Access Points to manage application access.</li> <li>Max I/O performance mode is used to scale to higher levels of aggregate throughput and operations per second \u2014 tradeoff of slightly higher latencies.</li> <li>General Purpose performance mode is ideal for latency-sensitive use cases.</li> <li>POSIX is compliant.</li> <li>Provisioned Throughput mode: for applications with high throughput to storage (MiB/s per TiB) ratios or with requirements greater than those allowed by the Bursting Throughput mode.</li> <li>Bursting Throughput mode: designed to burst to high throughput levels for periods of time.</li> <li>Higher price point than EBS.</li> <li>The maximum days for the EFS lifecycle policy is 90.</li> </ul> <p>Amazon FSx for Lustre:</p> <ul> <li>Run the world\u2019s most popular high-performance file system.</li> <li>For machine learning, high-performance computing (HPC), video processing, and financial modeling.</li> <li>Ability to both process the \u2018hot data\u2019 in a parallel and distributed fashion as well as easily store the \u2018cold data\u2019 on Amazon S3.</li> </ul>"},{"location":"AWS/Cheatsheet/#rds","title":"RDS","text":"<ul> <li>Multi A-Z synchronous replication across AZs. Replication between the primary and standby instances does not incur additional data transfer charges.</li> <li>Read replicas asynchronous replication across AZs or cross-region, up to 5.</li> </ul> <p>RDS Multi-AZ, Multi-region, Read Replicas Comparison</p> <ul> <li>Backups every 5min, ability to restore at any point in time.</li> <li>Supports storage autoscaling.</li> <li>IAM database authentication works with MySQL and PostgreSQL. Use an authentication token with a lifetime of 15 minutes.</li> <li>RDS provides metrics in real-time for the operating system (OS) that your DB instance runs on with Enhanced Monitoring(RDS processes, RDS child processes, OS processes).</li> <li>To encrypt unencrypted RDS database: create a snapshot of your DB instance, and then create an encrypted copy of that snapshot, restore DB from an encrypted snapshot, terminate the previous DB.</li> <li>Upgrades to the database engine level require downtime. Even if your RDS DB instance uses a Multi-AZ deployment, both the primary and standby DB instances are upgraded at the same time. This causes downtime until the upgrade is complete, and the duration of the downtime varies based on the size of your DB instance.</li> <li>RDS applies OS updates by performing maintenance on the standby, then promoting the standby to primary, and finally performing maintenance on the old primary, which becomes the new standby.</li> <li>The maximum backup retention period for automated backup is 35 days.</li> </ul> <p>Aurora</p> <ul> <li>Auto-scales up to 128 TB per database instance.</li> <li>Aurora cluster: one Primary DB instance \u2014 up to 15 replicas(read-only).</li> </ul> <p></p> <p>Aurora Cluster</p> <ul> <li>You can specify the failover priority for Aurora Replicas; each Read Replica is associated with a priority tier (0\u201315). Aurora will promote the Read Replica that has the highest priority (the lowest numbered tier). If two or more Aurora Replicas share the same priority, then Amazon RDS promotes the replica that is the largest in size.</li> <li>Aurora Global Database is designed for globally distributed applications, allowing a single Amazon Aurora database to span multiple AWS regions, sub-second data access in any region.</li> <li>Storage automatically grows in increments of 10GB.</li> <li>In a multi-master cluster, all DB instances can perform write operations(scale writes, avoid downtime for writes) \u2014 continuous availability for applications where you can\u2019t afford even brief downtime for database write operations.</li> <li>Using endpoints, you can map each connection to the appropriate instance or group of instances based on your use case. For clusters with DB instances of different capacities or configurations, you can connect to custom endpoints associated with different subsets of DB instances.</li> <li>Reader endpoint automatically performs load-balancing among all the Aurora Replicas.</li> <li>For diagnosis or tuning, you can connect to a specific instance endpoint to examine details about a specific DB instance.</li> <li>If you are running Aurora Serverless and the DB instance or AZ becomes unavailable, Aurora will automatically recreate the DB instance in a different AZ.</li> <li>If you have a single instance, Aurora will attempt to create a new DB Instance in the same Availability Zone as the original instance. This replacement of the original instance is done on a best-effort basis and may not succeed.</li> </ul>"},{"location":"AWS/Cheatsheet/#dynamodb","title":"DynamoDB","text":"<ul> <li>DynamoDB Accelerator (DAX) is a fully managed, highly available, in-memory cache for Amazon DynamoDB that delivers up to a 10 times performance improvement \u2014 from milliseconds to microseconds.</li> <li>Tables must have provisioned read and write capacity units RCU, WRC.</li> <li>DynamoDB Streams allow changes in DynamoDB to be streamed to other services(read by Lambda etc., 24h retention on streams).</li> <li>Global Tables support multi-region replication, low latency, disaster recovery. Must first enable Streams.</li> <li>Can only query on the primary key, sort key, or indexes.</li> <li>All DynamoDB tables are encrypted. There is no option to enable or disable encryption for new or existing tables. By default, all DynamoDB tables are encrypted under an AWS owned customer master key (CMK), which does not write to CloudTrail logs.</li> <li>If the shard iterator expires immediately before you can use it, this might indicate that the DynamoDB table used by Kinesis does not have enough capacity to store the lease data. To solve, increase the write capacity assigned to the shard table.</li> </ul>"},{"location":"AWS/Cheatsheet/#elasticache","title":"Elasticache","text":"<ul> <li>For sub-millisecond latency caching, ElastiCache is the best choice.</li> </ul> <p>Memcached</p> <ul> <li>Supports multithreaded architecture.</li> </ul> <p>Redis</p> <ul> <li>Redis HIPAA compliant, supports replication, high availability, and cluster sharding.</li> <li>The in-memory data store that provides sub-millisecond latency.</li> <li>IAM Auth is not supported by ElastiCache.</li> <li>Redis AUTH(enable Redis to require a token (password) before allowing clients to execute commands, thereby improving data security).</li> </ul>"},{"location":"AWS/Cheatsheet/#redshift","title":"Redshift","text":"<ul> <li>With Spectrum, you can efficiently query and retrieve structured and semistructured data from files in Amazon S3 without having to load the data into Amazon Redshift tables.</li> </ul> <p>Redshift Spectrum</p> <ul> <li>For OLAP: online analytical processing.</li> <li>Redshift enhanced VPC routing; copy/unload goes through VPC.</li> <li>Possibility to copy snapshots for a cluster to another region for DR.</li> </ul>"},{"location":"AWS/Cheatsheet/#cloudwatch","title":"Cloudwatch","text":"<ul> <li>Metrics belong to namespaces; Dimension is an attribute of a metric, Up to 10 dimensions per metric.</li> <li>Automatically recover ec2: If your instance has a public IPv4 address, it retains the public IPv4 address after recovery. During instance recovery, the instance is migrated during an instance reboot, and any data that is in-memory is lost.</li> <li>You can use CloudWatch Events to run Amazon ECS tasks when certain AWS events occur.</li> </ul> <p>EventBridge</p> <ul> <li>Recommended when you want to build an application that reacts to events from SaaS applications and/or AWS services. Only event-based service that integrates directly with third-party SaaS partners.</li> </ul>"},{"location":"AWS/Cheatsheet/#encryptionsecrets","title":"Encryption/Secrets","text":"<ul> <li>Key Policies: control access to keys; you cannot control access without them.</li> <li>Automatic key rotation: CMK every one year.</li> <li>SSE-KMS is a service that combines secure, highly available hardware and software to provide a key management system scaled for the cloud. When you use server-side encryption with AWS KMS (SSE-KMS), you can specify a customer-managed CMK that you have already created. SSE-KMS provides you with an audit trail that shows when your CMK was used and by whom.</li> <li>Deleting a customer master key (CMK) has enforced a waiting period; you schedule key deletion(minimum of 7 days up to a maximum of 30 days(default))</li> <li>SSE-C \u2014 With Server-Side Encryption with Customer-Provided Keys (SSE-C), you manage the encryption keys, and Amazon S3 manages the encryption, as it writes to disks and decryption when you access your objects.</li> <li>SSE-S3 \u2014 When you use Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3), each object is encrypted with a unique key. Uses 256-bit Advanced Encryption Standard (AES-256).</li> <li>Client-side encryption when there is a proprietary encryption algorithm.</li> </ul> <p>Secrets Manager</p> <ul> <li>Nice RDS integration.</li> <li>Force secret rotation every X days.</li> </ul> <p>SSM Parameter Store</p> <ul> <li>Allow assigning TTL to a parameter(expiration date) to force update/delete of sensitive data.</li> </ul> <p>CloudHSM</p> <ul> <li>With dedicated hardware, you manage your own encryption keys.</li> <li>A good option to use with SSE-C.</li> <li>It is possible to lose keys that were created since the most recent daily backup if the CloudHSM cluster that you are using fails and you are not using two or more HSMs.</li> </ul>"},{"location":"AWS/Cheatsheet/#kinesis","title":"Kinesis","text":"<p>Kinesis Data Streams</p> <ul> <li>Default data retention 1 day can go up to 7.</li> <li>1MB/sec/shard ingest capacity.</li> <li>By default, the 2MB/second/shard output is shared between all of the applications consuming data from the stream.</li> <li>Use enhanced fan-out if you have multiple consumers retrieving data from a stream in parallel, automatically scales throughput with the number of shards.</li> <li>The ability for multiple apps to consume the same stream concurrently.</li> <li>Ability to consume records in the same order a few hours later.</li> <li>Routing related records to the same record processor. For example, counting and aggregation are simpler when all records for a given key are routed to the same record processor.</li> </ul> <p>Kinesis Firehose</p> <ul> <li>It automatically scales to match the throughput of your data and requires no ongoing administration. The auto-scaling solution, as there is no need to provision any shards like Kinesis Data Streams.</li> <li>Kinesis Agent cannot write to a Kinesis Firehose for which the delivery stream source is already set as Kinesis Data Streams.</li> <li>Data into Amazon S3, Amazon Redshift, Amazon Elasticsearch Service, generic HTTP endpoints and Datadog, New Relic, MongoDB, Splunk.</li> <li>Load streaming data into Redshift for near real-time analytics.</li> </ul>"},{"location":"AWS/Cheatsheet/#sqs","title":"SQS","text":"<ul> <li>When you need messaging semantics(ack/fail) and visibility timeout(default 30s).</li> <li>Dynamically increasing concurrency/throughput at read time.</li> <li>FIFO queues support up to 3,000 messages(batch 10 messages per operation- max) per second with batching(300 without), have an 80-character queue name limit.</li> <li>Message retention 4 days default, 14 days max.</li> <li>Limit 256kb per message sent.</li> <li>To scale to the same number of consumers as producers, send data with a Group ID attribute.</li> <li>Delay queues let you postpone the delivery of new messages to a queue for several seconds. The default (minimum) delay for a queue is 0 seconds. The maximum is 15 minutes.</li> <li>You can use message timers to set an initial invisibility period for a message added to a queue. Default delay for a message in 0 seconds. The maximum is 15 minutes.</li> <li>Temporary queues help you save development time and deployment costs when using common message patterns such as request-response. To better support short-lived, lightweight messaging destinations, AWS recommends Amazon SQS Temporary Queue Client. The key concept behind the client is the Virtual Queue. Virtual queues let you multiplex many low-traffic queues onto a single SQS queue.</li> </ul> <p>SQS Virtual Queues</p> <ul> <li>AWS recommends using separate queues to provide prioritization of work.</li> <li>A single SQS message queue can contain an unlimited number of messages. However, there is a 120,000 quota for the number of inflight messages for a standard queue and 20,000 for a FIFO queue. Messages are inflight after they have been received from the queue by a consuming component but have not yet been deleted from the queue.</li> <li>Standard queues provide at least one delivery, which means that each message is delivered at least once.</li> <li>FIFO queues provide exactly-once processing, which means that each message is delivered once and remains available until a consumer processes it and deletes it. Duplicates are not introduced into the queue.</li> <li>An Amazon SQS message can contain up to 10 metadata attributes.</li> <li>By default, ReceiveMessageWaitTimeSeconds is zero, which means it is using Short polling. If it is set to a value greater than zero, then it is Long polling.</li> </ul>"},{"location":"AWS/Cheatsheet/#sns","title":"SNS","text":"<ul> <li>Event producers send events to 1 topic; we can have many subs.</li> <li>100000 topics limit</li> <li>Use SNS message filtering to assign a filter policy to the topic subscription, and the subscriber will only receive a message that they are interested in.</li> <li>SNS FIFO for strict message ordering and deduplicated message delivery to one or more subscribers</li> </ul> <p>SNS FIFO</p>"},{"location":"AWS/Cheatsheet/#loadbalancers","title":"LoadBalancers","text":"<ul> <li>LBs can scale but not instantaneously.</li> <li>Elastic Load Balancing stops sending requests to targets that are deregistering. By default, Elastic Load Balancing waits 300s(can be set between 1s to 3600s) seconds before completing the deregistration process, which can help in-flight requests to the target to complete(connection drain).</li> <li>When cross-zone load balancing is enabled, each load balancer node distributes traffic across the registered targets in all enabled Availability Zones evenly.</li> </ul> <p>Cross-Zone Load Balancing Enabled</p> <ul> <li>By default, cross-zone load balancing is enabled for Application Load Balancer and disabled for Network Load Balancer.</li> <li>ELB cannot distribute incoming traffic for targets deployed in different regions.</li> <li>Access logging is an optional feature of Elastic Load Balancing that is disabled by default. Use to analyze traffic patterns and troubleshoot issues.</li> </ul> <p>Application LoadBalancer</p> <ul> <li>ALB targets with instance ID route to primary private IP in primary NIC targets using IP addresses route to any private IP from one or more NICs.</li> <li>Host-based Routing: You can route a client request based on the Host field of the HTTP header, allowing you to route to multiple domains from the same load balancer.</li> <li>Path-based Routing: You can route a client request based on the URL path of the HTTP header.</li> <li>HTTP header-based routing: You can route a client request based on the value of any standard or custom HTTP header.</li> <li>HTTP method-based routing: You can route a client request based on any standard or custom HTTP method.</li> <li>Query string parameter-based routing: You can route a client request based on the query string or query parameters.</li> <li>Source IP address CIDR-based routing: You can route a client request based on source IP address CIDR from where the request originates.</li> <li>ALB not registered any targets with the target groups -&gt; 503 error.</li> <li>Use Cognito Authentication via Cognito User Pools for your ALB.</li> <li>With SNI support AWS makes it easy to use more than one certificate with the same ALB.</li> <li>You can host multiple TLS secured applications, each with its own TLS certificate, behind a single ALB. In order to use SNI, all you need to do is bind multiple certificates to the same secure listener on your load balancer. ALB will automatically choose the optimal TLS certificate for each client.</li> <li>ALBs support Weighted Target Groups routing.</li> </ul> <p>Network LoadBalancer</p> <ul> <li>NLB traffic is routed using the private IP address.</li> <li>Network LB has no security groups, it lets traffic passing by.</li> <li>With Network Load Balancer (NLB), you can offload the decryption/encryption of TLS traffic from your application servers to the NLB.</li> </ul> <p>Classic LoadBalancer</p> <ul> <li>CLB does not support Server Name Indication (SNI).</li> </ul>"},{"location":"AWS/Cheatsheet/#lambda","title":"Lambda","text":"<ul> <li>Supports 1000 concurrent executions per AWS account per region, contact support to raise the limit if needed.</li> <li>Supported languages: C#/.NET, GO, node.js, Python, Java, Ruby.</li> <li>lamda@edge: deploy lambda to each region alongside your CloudFront CDN.</li> <li>You can set your memory from 128MB to 10,240MB</li> <li>If your Lambda function accesses a VPC, you must make sure that your VPC has sufficient ENI or subnect IPs capacity to support the scale requirements of your Lambda function.</li> </ul> <p>Step Functions</p> <ul> <li>Serverless workflows orchestration.</li> </ul>"},{"location":"AWS/Cheatsheet/#cloudfront","title":"Cloudfront","text":"<ul> <li>Delivering data out of CloudFront can be more cost-effective than delivering it from S3 directly to your users.</li> <li>Use CloudFront to improve application performance to serve static content from S3.</li> <li>Dynamic content does not flow through regional edge caches but goes directly to the origin \u2014 Proxy methods PUT/POST/PATCH/OPTIONS/DELETE go directly to the origin.</li> <li>Preferred to handle spikes in traffic over GA.</li> <li>You cannot directly integrate Cognito User Pools with CloudFront distribution as you have to create a separate Lambda@Edge function to accomplish the authentication via Cognito User Pools.</li> <li>CloudFront can route to multiple origins based on the content type.</li> <li>Field-level encryption: The sensitive information provided by your users is encrypted at the edge (You can\u2019t encrypt all of the data in a request with field-level encryption; you must specify individual fields to encrypt).</li> <li>CloudFront signed cookies -&gt; provide access to multiple restricted files.</li> <li>CloudFront signed URLs -&gt; access to one file.</li> <li>You can also use an EC2 instance or a custom origin in configuring CloudFront.</li> <li>The Cache-Control and Expires headers control how long objects stay in the cache. The Cache-Control max-age directive lets you specify how long (in seconds) you want an object to remain in the cache before CloudFront gets the object again from the origin server. The minimum expiration time CloudFront supports is 0 seconds for web distributions and 3600 seconds for RTMP distributions.</li> </ul>"},{"location":"AWS/Cheatsheet/#global-acceleratorga","title":"Global Accelerator(GA)","text":"<ul> <li>Directs traffic to optimal endpoints over the AWS global network.</li> <li>Improves the availability and performance of your internet applications.</li> <li>Two static anycast IP addresses act as a fixed entry point to your application endpoints.</li> </ul> <p>Global Accelerator Overview</p> <ul> <li>Good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or Voice over IP.</li> <li>Uses endpoint weights to determine the proportion of traffic that is directed to endpoints in an endpoint group(can be used in blue/green deployments).</li> </ul> <p></p> <p>Global Accelerator Weighted Endpoints</p> <p>WAF</p> <ul> <li>Use AWS WAF to block or allow requests based on conditions that you specify, such as the IP addresses.</li> <li>Geographic (Geo) Match Conditions in AWS WAF to restrict application access based on the geographic location of your viewers \u2014 choose the countries from which AWS WAF should allow access.</li> <li>Protects against SQL injection and Cross-Site Scripting.</li> <li>Rate based rules(DDoS protection).</li> </ul> <p>Firewall Manager</p> <ul> <li>Centrally configure and manage firewall rules across your accounts and applications in AWS Organizations.</li> <li>You can centrally configure AWS WAF rules, AWS Shield Advanced protection, Amazon Virtual Private Cloud (VPC) security groups, AWS Network Firewalls, and Amazon Route 53 Resolver DNS Firewall rules across accounts and resources in your organization. It does not support Network ACLs as of today.</li> </ul> <p>AWS Shield</p> <ul> <li>DDoS, protection against SYN/UDP floods, reflection attacks, and other layer/3 &amp; layer 4 attacks.</li> </ul> <p>EMR</p> <ul> <li>Cloud big data platform for processing vast amounts of data using Apache Spark, Apache Hive, Apache HBase, Apache Flink, Apache Hudi, and Presto, Hadoop.</li> </ul> <p>Beanstalk</p> <ul> <li>Easy-to-use service for deploying and scaling web applications and services developed with Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker.</li> <li>Automatically handles the deployment, from capacity provisioning, load balancing, auto-scaling to application health monitoring.</li> <li>You retain full control over the AWS resources powering your application and can access the underlying resources at any time.</li> <li>Application files are stored in S3. The server log files can also optionally be stored in S3 or in CloudWatch Logs.</li> </ul> <p>CloudFormation</p> <ul> <li>StackSet extends the functionality of stacks by enabling you to create, update, or delete stacks across multiple accounts and regions with a single operation.</li> <li>Use the CreationPolicy attribute when you want to wait on resource configuration actions before stack creation proceeds.</li> </ul>"},{"location":"AWS/Cheatsheet/#cognito","title":"Cognito","text":"<p>User pools</p> <ul> <li>Provide built-in user management e.g., sign-in and register functionality for apps.</li> </ul> <p>Identity pools</p> <ul> <li>Provide temporary credentials for AWS access to users.</li> </ul> <p>AWS Database Migration Service</p> <ul> <li>Seamlessly migrate data from supported sources to relational databases, data warehouses, streaming platforms, and other data stores in the AWS cloud. (e.g., quickly move data from S3 to Kinesis data streams, not only for DBs).</li> </ul> <p></p> <p>Database Migration Service Use Case: Migrate data from S3 to Kinesis</p>"},{"location":"AWS/Cheatsheet/#storage-gateway","title":"Storage Gateway","text":"<p>File Gateway</p> <p></p> <p>File Gateway Architecture</p> <ul> <li>SMB or NFS access to data in S3 with local caching.</li> </ul> <p>Volume Gateway</p> <ul> <li>Present cloud-based iSCSI block storage volumes to your on-premises applications.</li> </ul> <p>Tape Gateway</p> <ul> <li>Supports archiving directly to Glacier and Glacier Deep Archive.</li> </ul> <p>DataSync</p> <ul> <li>Move large data from on-premise to AWS.</li> <li>Can move data directly to Glacier or Glacier Deep Archive.</li> </ul> <p>AppSync</p> <ul> <li>Store and sync data across mobile and web apps in real-time.</li> </ul> <p>CloudTrail</p> <ul> <li>By default, CloudTrail event log files are encrypted using Amazon S3 server-side encryption (SSE).</li> </ul> <p>Xray</p> <ul> <li>AWS X-Ray helps developers analyze and debug production, distributed applications, such as those built using a microservices architecture.</li> <li>End-to-end view of requests as they travel through your application, and shows a map of your application\u2019s underlying components.</li> <li>The X-Ray agent can assume a role to publish data into an account different from the one in which it is running.</li> </ul> <p>GuardDuty</p> <ul> <li>Threat detection that enables you to continuously monitor and protect your AWS accounts, workloads, and data stored in Amazon S3.</li> <li>Analyses AWS CloudTrail Events, Amazon VPC Flow Logs, and DNS Logs.</li> <li>Disabling the service in the general settings deletes all the remaining data.</li> </ul> <p>Macie</p> <ul> <li>Discover and protect your sensitive data on Amazon S3.</li> </ul> <p>Inspector</p> <ul> <li>Helps you check for unintended network accessibility of your Amazon EC2 instances and for vulnerabilities on those EC2 instances.</li> </ul> <p>Recognition</p> <ul> <li>Automate your image and video analysis with machine learning.</li> </ul>"},{"location":"AWS/Cheatsheet/#vpc-endpoints","title":"VPC Endpoints","text":"<ul> <li>When you create a VPC endpoint, you can attach an endpoint policy that controls access to the service to which you are connecting.</li> </ul> <p>Gateway Endpoints</p> <ul> <li>GE is a gateway that you specify as a target for a route in your route table for traffic destined to a supported AWS service.</li> <li>S3 &amp; DynamoDB only.</li> </ul> <p>Interface Endpoints</p> <ul> <li>An elastic network interface with a private IP address from the IP address range of your subnet that serves as an entry point for traffic destined to a supported service.</li> </ul>"},{"location":"AWS/Cheatsheet/#enhanced-networking","title":"Enhanced Networking","text":"<p>Elastic Network Adapter(ENA)</p> <ul> <li>Enhanced networking capabilities with network speeds of up to 100 Gbps.</li> <li>Supports Windows.</li> </ul> <p>Elastic Fabric Adapter (EFA)</p> <ul> <li>Network device that you can attach to your Amazon EC2 instance to accelerate <code>High-Performance Computing (HPC)</code> and machine learning applications.</li> <li>ENA with added capabilities.</li> <li>Doesn\u2019t support Windows.</li> <li>EFA support can be enabled either at the launch of the instance or added to a stopped instance. EFA devices cannot be attached to a running instance.</li> </ul> <p>API Gateway</p> <ul> <li>Rest APIs \u2014 stateful client-server communication.</li> <li>Websocket APIs \u2014 stateless full-duplex communication.</li> <li>All of the APIs created with Amazon API Gateway expose HTTPS endpoints only</li> </ul> <p>SWF Simple Workflow Service</p> <ul> <li>Use if you need: external signals to intervene, or child processes to return values to parent processes.</li> <li>For decoupled architectures.</li> <li>Provides useful guarantees around task assignments. It ensures that a task is never duplicated and is assigned only once.</li> </ul> <p>AWS Backup</p> <ul> <li>Centralized backup service.</li> <li>A backup plan is a policy expression that defines when and how you want to back up your AWS resources.</li> </ul> <p>AWS Batch</p> <ul> <li>Multi-node parallel jobs.</li> </ul> <p>AWS ParallelCluster</p> <ul> <li>Cluster management tool to deploy HPC, automate creation of vpc, subnet, cluster type etc.</li> </ul> <p>AD Connector</p> <ul> <li>If you only need to allow your on-premises users to log in to AWS applications and services with their Active Directory credentials.</li> </ul> <p>AWS Managed Microsoft AD</p> <ul> <li>Configure a trust relationship between AWS Managed Microsoft AD in the AWS Cloud and your existing on-premises Microsoft Active Directory, providing users and groups with access to resources in either domain, using single sign-on (SSO).</li> </ul> <p>Data Transfer</p> <ul> <li>No charge for inbound data transfer across all services in all Regions.</li> <li>Data transfer from AWS to the internet is charged per service, with rates specific to the originating Region.</li> <li>There is a charge for data transfer across Regions.</li> <li>Data transfer within the same Availability Zone is free.</li> <li>Data transfer over a VPC peering connection that stays within an Availability Zone is free. Data transfer over a VPC peering connection that crosses Availability Zones will incur a data transfer charge for ingress/egress traffic. If the VPCs are peered across Regions, standard inter-Region data transfer charges will apply.</li> <li>Data processing charges apply for each GB sent from a VPC, Direct Connect, or VPN to Transit Gateway.</li> <li>Direct Connect &amp; VPN also incur charges for data flowing out of AWS.</li> </ul> <p>Important ports:</p> <ul> <li>FTP: 21</li> <li>SSH: 22</li> <li>SFTP: 22 (same as SSH)</li> <li>HTTP: 80</li> <li>HTTPS: 443</li> <li>RDP: TCP 3389 and UDP 3389</li> </ul> <p>RDS Databases ports:</p> <ul> <li>PostgreSQL: 5432</li> <li>MySQL: 3306</li> <li>Oracle RDS: 1521</li> <li>MSSQL Server: 1433</li> <li>MariaDB: 3306 (same as MySQL)</li> <li>Aurora: 5432 (if PostgreSQL compatible) or 3306 (if MySQL compatible)</li> </ul>"},{"location":"AWS/Cheatsheet/#disaster-recovery-in-aws","title":"Disaster Recovery in AWS","text":"<ul> <li>RPO: Recovery Point Objective -&gt; how much data loss we are willing to recover</li> <li>RTO: Recovery Time Objective -&gt; downtime between disaster and RTO</li> </ul>"},{"location":"AWS/Networking/","title":"Networking","text":""},{"location":"AWS/Networking/#classful-network","title":"Classful Network","text":"<ul> <li>This is pre-cursor to the CIDR</li> <li>The IPv4 address were divided into 4 classes.</li> </ul> Class IPs Start IP End IP Mask Equivalent CIDR Notation A 2^24 0.0.0.0 127.255.255.255 255.0.0.0 /8"},{"location":"Books/English/","title":"English","text":"<ul> <li>John was a big deal - the operative word being \"was\".</li> </ul>"},{"location":"Books/Jerks%20At%20Work/","title":"Jerks at work","text":"<p>Jerks at Work by Tessa West is a practical guide for understanding and dealing with difficult coworkers. West uses psychological research to offer strategies for navigating toxic work environments and building healthier relationships.</p> <p>Key Points:</p> <ul> <li>Understanding Jerks: The book categorizes jerks into different types, such as the A-hole, Know-It-All, Slacker, Overbearing Boss, and Passive-Aggressive.</li> <li>Identifying Jerks: West provides tools to recognize these behaviors and understand the underlying motivations.</li> <li>Dealing with Jerks: The book offers practical advice for handling difficult situations, including setting boundaries, communicating effectively, and seeking support.</li> <li>Protecting Yourself: West emphasizes the importance of self-care and maintaining emotional well-being in toxic environments.</li> <li>Creating a Positive Workplace: The book encourages readers to foster a supportive and respectful work culture.</li> </ul> <p>Key Strategies: - Set Boundaries: Clearly communicate your expectations and limits to prevent jerks from crossing lines. - Use \"I\" Statements: Express your feelings and concerns in a non-accusatory manner. - Document Interactions: Keep a record of incidents to protect yourself and build a case if necessary. - Seek Support: Talk to a trusted colleague, mentor, or HR representative. - Focus on Your Goals: Remember your career aspirations and stay focused on your own success.</p>"},{"location":"Books/Jerks%20At%20Work/#1-kiss-up-kick-downer","title":"1. Kiss Up / Kick Downer","text":""},{"location":"Books/Jerks%20At%20Work/#who","title":"Who","text":"<ul> <li>They belittle you in front of the people you are trying to impress.</li> <li>They reserve the nastiest behavior for one-on-one time.</li> <li>If your boss is overwhelmed/overworked and need favors, they are quick to offer help.</li> <li>They approach high power people outside of work.</li> </ul>"},{"location":"Books/Jerks%20At%20Work/#why","title":"Why","text":"<p>To get to the top by any means.</p>"},{"location":"Books/Jerks%20At%20Work/#how-to-deal","title":"How to deal?","text":"<ul> <li>Find who else might have been the victims. This can be found through a well-connected ally or talking with others w/o bringing up the topic directly.</li> <li>Document the facts and build your proofs.</li> <li>Talk to the supervisor that how such behavior is bad for \"our work environment\" and lead them to seek feedback from other victims.</li> <li>Be patient and wait. Real result takes time.</li> <li>If you are a boss, give everyone equal shots.</li> </ul>"},{"location":"Books/Jerks%20At%20Work/#2-credit-stealers","title":"2. Credit-Stealers","text":""},{"location":"Books/Jerks%20At%20Work/#who_1","title":"Who","text":"<ul> <li>Opportunistic who use the group settings where credits are not tracked; to steal the credit.</li> <li>Sometimes the credit-stealers are smart people who can exploit your half-backed idea, refine and present it to the bosses.</li> <li>Sometimes credit-stealing is non-intentional. Our personal biases (such as over-estimating our contribution) can feel that credit-stealing is justified.</li> </ul>"},{"location":"Books/Jerks%20At%20Work/#how-to-deal_1","title":"How to deal?","text":"<ul> <li>Cultivate your voice  ie become respected by your coworkers and your boss even before you enter the room. Become advice tie ie someone who are sought out for advice. Advice tie is not same as friendship tie. Don't make friends, that can backfire. </li> <li>Confront the credit stealer: \"What is your perspective on the idea?\"</li> <li>In team setting, allocate the work and then record who did what well before the outcome is available ie credit the work put in and not the success of the outcome.</li> </ul>"},{"location":"Books/Jerks%20At%20Work/#3-micro-manager","title":"3. Micro-manager","text":""},{"location":"Books/Jerks%20At%20Work/#who_2","title":"Who","text":"<ul> <li>They ask you to do more work but without a reasonable timeline. Everything is equally urgent and must be done now.</li> <li>They are bad at communicating the big picture.</li> <li>They are too much focused on trees (and their shape) and miss the forest.</li> <li>If they micro-manage people in rotations, this leads to neglectful behavior.</li> </ul>"},{"location":"Books/Jerks%20At%20Work/#why_1","title":"Why","text":"<ul> <li>They were good at their old job and got promoted, not because they are good at directing people. They have no ideas for you, so they keep you busy (but not productive)</li> <li>They believe more monitoring equals more performance.</li> <li>Sometimes they fear mistakes (and want to avoid them)</li> </ul>"},{"location":"Books/Jerks%20At%20Work/#how-to-deal_2","title":"How to deal?","text":"<ul> <li>If you confront, avoid generalization and use the specific examples.</li> <li>Set up regular check-ins.</li> <li>Ask the big picture: how does what I do matter in the big picture?</li> </ul>"},{"location":"Books/Staff%20Engineer%20Path/","title":"Staff Engineer Path","text":"<ul> <li>oreilly book </li> <li>Tanya Reilly  </li> </ul>"},{"location":"Books/Staff%20Engineer%20Path/#pillars-of-staff-engineeringindividual-contributor-path","title":"Pillars of Staff Engineering/Individual Contributor Path","text":"<ul> <li> <p>While there are many books and help available to guide on the people management path, there is ambiguity on what is expected from the IC. There are 3 pillars for the IC role:  </p> </li> <li> <p>Big-picture Thinking - It means broader view of the context, predicting the yearlong, post-execution needs.  </p> </li> <li>Execution - It's messier at this level, you need political capital and influence to succeed.  </li> <li>Leveling Up - Raising the standard and skills of the engineers. This could be through teaching, mentoring, being a role model.  </li> </ul> <p>The pillars stand on the solid foundation of the technical knowledge and the experience. The successful impact also require following skills (similar to building buttresses):  </p> <ul> <li>Communication and leadership  </li> <li>Navigating complexity  </li> <li>Putting your work in perspective  </li> <li>Mentorship, sponsorship, and delegation  </li> <li>Framing a problem so that other people care about it  </li> <li>Acting like a leader whether you feel like one or no  </li> </ul>"},{"location":"Books/Staff%20Engineer%20Path/#big-picture","title":"Big-picture","text":""},{"location":"Books/Staff%20Engineer%20Path/#what-do-staff-engineers-do","title":"What do Staff Engineers do?","text":"<ul> <li>Staff engineering roles are ambiguous by definition. It\u2019s up to you to discover and decide what your role is and what it means for you.  </li> <li>TPMs (Technical Project Manager aka Team Lead) are responsible for delivery, not design, and not engineering quality. TPMs make sure the project gets\u00a0done on time, but staff engineers make sure it\u2019s done with high engineering standards.  </li> <li>As \u00a0your time becomes more and more expensive, the work you do is expected to be more valuable and have a greater impact.  </li> <li>You\u2019re probably not a manager, but you\u2019re in a leadership role.. </li> <li>YES, YOU CAN BE AN INTROVERT. NO, YOU CAN\u2019T BE A JERK. </li> <li> <p>4 Skills that you need (compare with a restaurant)  </p> </li> <li> <p>Coding (Cooking)  </p> </li> <li>Product Management (Menu item)  </li> <li>Project Management (Lunch/Dinner/B'day)  </li> <li> <p>People Management (Manage Cooks, Chefs)  </p> </li> <li> <p>You\u2019re also in a role that requires technical judgment and solid technical experience.  </p> </li> <li>Be clear about your scope: your area of responsibility and influence.  </li> <li>Your time is finite. Be deliberate about choosing a primary focus that\u2019s important and that isn\u2019t wasting your skills.  </li> <li>Align with your management chain. Discuss what you think your job is, see what your manager thinks it is, understand what\u2019s valued and what\u2019s actually useful, and set expectations explicitly. Not all companies need all shapes of staff engineers.  </li> <li>Your job will take a weird shape sometimes, and that\u2019s OK.  </li> </ul>"},{"location":"Books/Staff%20Engineer%20Path/#3-maps","title":"3 Maps","text":"<p>There are 3 maps you would need:</p> <ol> <li>Locator Map - Zoom out to know where the team is and what's its place in the org. This would  isolate and remove the importance of the local problems.</li> <li>Treasure Map - It's the destination. You should be able to tell a compelling story of the treasure available at the destination. </li> <li>Topographical Map - Direction and navigation through the terrain to the destination. You should be able to see the path to get there and the challenges/wins that would happen on the way. What support and friction that you would run into. </li> </ol> <p>The secrets to these maps lie in the culture. But What is culture? </p> <ul> <li>Open or Secret? Does information available openly? Is interaction possible eg slack?  </li> <li>Oral vs Written : are decisions shared written down or orally?  </li> <li>top-down or bottom-up : where do initiatives come from?  </li> <li>Are changes made fast or slow?  </li> <li> <p>Are the seats of power crystalized or liquid?</p> </li> <li> <p>Practice the skills of intentionally looking for a bigger picture and seeing what\u2019s happening.  </p> </li> <li>Understand your work in context: know your customers, talk with peers outside your group, understand your success metrics, and be clear on what\u2019s actually important.  </li> <li>Know how your organization works and how decisions get made within it.  Try to get invited into that \"the room\" but then figure out the \"shadow org\" (un-written structures through which power and influence flow) - the one that meet unofficially and make decisions.</li> <li>Build or discover paths to allow information you need to come to you.  </li> <li>Be clear about what goals everyone is aiming for.  </li> <li>Think about your own work and what your journey is.</li> </ul>"},{"location":"Books/Staff%20Engineer%20Path/#creating-the-big-picture","title":"Creating the Big Picture","text":"<ul> <li>If everyone is working off the same big picture, your work is done. If not, you need to create a big picture and share with all.</li> <li>Technical Vision = what the future looks like after the work is done, problems are solved.</li> <li>Technical Strategy = plan of action, challenges to overcome. It should cover:<ul> <li>Diagnosis = What's going on? Identify the pattern behind the noise, the essential characteristic of the situation.</li> <li>Guiding Policy = What should be the guiding light when you face obstacles to overcome the diagnosis.</li> <li>Coherent Action = Specific action (technical, process or people)</li> </ul> </li> <li>Documenting vision/strategy takes time (iteration, alignment) and could be a overkill when you can get the team on the same page in a single meeting.</li> <li>If someone is already working on it, share the lead or follow their lead or step away.</li> <li>Initial ideas -&gt; write &gt; talk to key people &gt; revise (make decisions, trade-offs) until it's ready to publish/share with the broader group.</li> </ul>"},{"location":"Books/The%20Effective%20Engineer/","title":"Effective Engineer - Notes","text":"<ul> <li>By Edmond Lau. Highly Recommended </li> <li>http://www.theeffectiveengineer.com/</li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#whats-an-effective-engineer","title":"What's an Effective Engineer?","text":"<ul> <li>They are the people who get things done. Effective Engineers produce results. </li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#adopt-the-right-mindsets","title":"Adopt the Right Mindsets","text":""},{"location":"Books/The%20Effective%20Engineer/#focus-on-high-leverage-activities","title":"Focus on High Leverage Activities","text":"<ul> <li>Leverage = Impact Produced / Time Invested</li> <li>Use Leverage as Your Yardstick for Effectiveness</li> <li>80% of the impact comes from 20% of the work.</li> <li>Focus on high leverage and not just easy wins.</li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#optimize-for-learning","title":"Optimize for Learning","text":"<ul> <li>Change jobs if you have to. </li> <li>Optimizing for learning is high leverage. </li> <li> <p>Adopt a growth mindset. </p> </li> <li> <p>Talk to people. Become good at telling stories. It gets better with time. </p> </li> <li>Those with a growth mindset believe that they can cultivate and grow their intelligence and skills through effort.</li> <li> <p>Own your story.</p> </li> <li> <p>Invest in the rate of learning</p> </li> <li> <p>Learning compounds. Compounding leads to exponential growth. Earlier the compounding starts, the better. </p> </li> <li>Working on unchallenging tasks is a huge opportunity cost. You missed out on compounded learning. </li> <li>Prioritize learning over profitability.</li> <li> <p>Invest your time in activities with the highest learning rate.</p> </li> <li> <p>Seek Work Environments Conducive to Learning</p> </li> <li> <p>Fast Growth: Companies where #problems &gt;&gt; #resources. Opportunity to choose high impact work.</p> </li> <li>Make sure you are working on high priority projects. </li> <li>Openness: Look for culture with curiosity, where everyone is encouraged to ask questions.</li> <li>Fast Paced. </li> <li>People smarter than you.</li> <li> <p>Autonomy: Freedom to choose what to work on. Smaller companies =&gt; More autonomy. </p> </li> <li> <p>While on Job</p> </li> <li> <p>Make a daily habit of acquiring new skills.</p> </li> <li>Read code written by brilliant engineers. </li> <li>Jump fearlessly into code you don't know.</li> <li>Always be learning. Invest in skills that are in high demand.</li> <li>Read Books. Attend Conferences.</li> <li>Build and maintain strong relationships.</li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#prioritize-regularly","title":"Prioritize Regularly","text":"<ul> <li>Opportunity cost of working on wrong ideas can set back growth by years.</li> <li>Prioritize tasks based on ROI.</li> <li>Regular prioritization is high leverage activity.</li> <li>On TODO Lists:</li> <li>Maintain a 'single' todo lists where all tasks are listed. </li> <li> <p>Don't try to remember stuff. Brain is bad at remembering. It's rather good at processing. </p> </li> <li> <p>Ask yourself regularly: Is this the most important thing I should be working on?</p> </li> <li>Focus on what directly produces value. </li> <li>Learn to say no.</li> <li>Focus on the important and non-urgent.</li> <li>Find ways to get into flow. \u201cA state of effortless concentration so deep that they lose their sense of time, of themselves, of their problems.\u201d</li> <li>When possible, preserve larger blocks of focused time in your schedule.</li> <li>Limit the amount of Work in Progress.</li> <li>Cost of context switching is high.</li> <li>Prioritizing is difficult. </li> <li>Prioritization is high leverage. It has huge impact on your ability to get right things done.</li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#invest-in-iteration-speed","title":"Invest in Iteration Speed","text":"<ul> <li>Continuous Deployment is high leverage.</li> <li>Will save a lot of time in manual deployment of code. They are the people who get things done. Effective Engineers produce results. </li> <li>Move fast to learn fast.</li> <li>Move fast and break things.</li> <li>Moving fast enables us to build more things and learn at faster rate. </li> <li>Invest in time saving tools.</li> <li>If you have to do something more than twice, write a tool the third time. </li> <li>Tools are multipliers that allow your to scale your impact beyond the confines of a day.</li> <li>Faster tools get used more often.</li> <li>Faster tools can enable new workflows that previously weren't possible.</li> <li>Productivity skyrockets with tools.</li> <li>Time saving property of tools also scale with team adoption.</li> <li>Shorten your debugging and validation Loops.</li> <li>Extra time spent in optimizing debugging workflow can help you fix annoying bugs with less headache.</li> <li>Debugging is hard. It's time consuming. Upfront investments to shorten debugging loops are worth it. </li> <li>High test coverage to reduce build and site breakages.</li> <li>Fast unit tests to encourage people to run them.</li> <li>Fast and incremental compiles and reloads to reduce development time.</li> <li>Master you programming environment.</li> <li>One editor. One high level language. Shell. Keyboard &gt; Mouse. Automate manual workflows. Use interactive shell. Make running specific tests easy.</li> <li>Faster you can iterate, faster you can learn. </li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#measure-what-you-want-to-improve","title":"Measure what you want to Improve","text":"<ul> <li>Use metric to drive progress.</li> <li>If you can't measure it, you can't improve it.</li> <li> <p>Good metric. </p> <ul> <li>Helps you focus on right things.</li> <li>Drives forward progress.</li> <li>Helps you guard against future regressions. </li> <li>Performance ratcheting: Any change should strictly improve the metric.  </li> <li>Bad metric can lead to unwanted behavior.</li> <li>Examples: </li> <li>number of hours worked &lt; productivity.</li> <li>click through rates &lt; long click through rates.</li> <li>Metric you choose influences your decisions and behavior.</li> <li>Look for metric that, when optimized, maximizes impact for the team.</li> <li>Actionable metric - Whose movement can be casually explained by team's effort.</li> <li>Responsive metric - Updates quickly to give back feedback whether a given change was =ve or -ive.</li> <li>Choosing a metric is high leverage.</li> <li>Dedicate time to pick right metric. </li> </ul> </li> <li> <p>Instrument everything to understand what's going on. </p> </li> <li>Measure anything, measure everything. </li> <li>Graphite, statsd. A single line of code lets you define a new counter or timer on the fly. </li> <li> <p>Measuring goals you want to achieve is high leverage.</p> </li> <li> <p>Internalize useful numbers.</p> </li> <li>Knowledge of useful numbers provide a valuable shortcut for knowing where to invest efforts to maximize gains.</li> <li>Need upfront work. Need not be accurate, ballpark idea suffices.</li> <li>Knowing useful numbers enables you to do back of the envelope calculations to quickly estimate the performance properties of a design without actually building it.</li> <li>Internalizing useful number help you spot anomalies.</li> </ul> <p>Be skeptical about data integrity.  - Log data liberally.  - Build tools to iterate on data accuracy sooner.  - Examine data sooner.  - When numbers look off, dig in to it sooner.</p> <p> Measure your progress. Carefully choose your top-level metric. Instrument your system. Know your numbers. Prioritize data integrity. </p>"},{"location":"Books/The%20Effective%20Engineer/#validate-your-ideas-early-and-often","title":"Validate your ideas early and often.","text":"<ul> <li>Not validating early leads to wasted efforts.</li> <li>Don't delay get feedback. </li> <li>Find low effort ways to validate work. </li> <li>Power of small batches. Helps you avoid making a big mistake by stopping the flow.</li> <li>Approach problem iteratively. </li> <li>No large implementations.</li> <li>Working solo? Be wary. Be extra vocal and get feedback.</li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#improve-project-estimation-skills","title":"Improve project estimation skills.","text":"<ul> <li>Beware of mythical man month. Communication overhead is significant. </li> <li>Reduce risk early.</li> <li>Rewrite projects - almost always fail. </li> <li>Additional hours hurt productivity. Causes burnout. </li> <li>Do the riskiest task first. </li> <li>Allow buffer room for the unknown.</li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#balance-quality-with-pragmatism","title":"Balance Quality with Pragmatism","text":"<ul> <li>High code quality. Code readability.</li> <li>Establish sustainable code review process.</li> <li>Code reviews help:</li> <li>Catch bugs and design problems early.</li> <li>Sharing working knowledge of the codebase.</li> <li>Increases long term agility. Easier to understand, quicker to modify. </li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#manage-complexity-through-abstraction","title":"Manage complexity through Abstraction","text":"<ul> <li>Example: MapReduce.</li> <li>Right abstractions make huge difference.</li> <li>\u201cPick the right ones, and programming will flow naturally from design; modules will have small and simple interfaces; and new functionality will more likely fit in without extensive reorganization,\u201d</li> <li>\u201cPick the wrong ones, and programming will be a series of nasty surprises: interfaces will become baroque and clumsy as they are forced to accommodate unanticipated interactions, and even the simplest of changes will be hard to make.\u201d</li> <li>The right abstraction can increase engineering productivity by an order of magnitude. </li> <li>Simple abstractions avoid interweaving multiple concepts, so that you can reason about them independently rather than being forced to consider them together.</li> <li>Designing good abstractions take work. </li> <li>An abstraction's usage and popularity provides a reasonable proxy for its quality.</li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#automate-testing","title":"Automate Testing","text":"<ul> <li>Unit test cases and some integration testing provide a scalable way of managing growing codebase.</li> <li>A suite of extensive and automated tests can reduce overall error rates by validating the quality and by safeguarding against regressions.</li> <li>Tests also allow engineers to make changes, especially large refactorings, with significantly higher confidence.</li> <li>Despite its benefits, it can be difficult to foster a culture of automated testing.</li> <li>Focus on high leverage tests. </li> <li>Writing more tests, creating a virtuous feedback cycle and saving more development time.</li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#repay-technical-debt","title":"Repay Technical Debt","text":"<ul> <li>Technical debt refers to all the deferred work that\u2019s necessary to improve the health and quality of the codebase and that would slow us down if left unaddressed.</li> <li>Accumulating technical debt is fine as far as it is repaid within time. </li> <li>Refactor often.</li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#reduce-operational-complexity","title":"Reduce Operational Complexity","text":"<ul> <li>Keep no. of technologies low. Don\u2019t sway towards shiny new technologies.</li> <li>Every additional technology you add is is guaranteed to go wrong eventually. Will need your time. </li> <li>Do the simple thing first.</li> <li>Embrace operational simplicity. </li> <li>The first solution that comes to mind is generally complex. Don't stop. Keep peeling off the layers of onion. </li> <li>Simplify the architecture to reduce their operational burden. </li> <li>\u201cWhat\u2019s the simplest solution that can get the job done while also reducing our future operational burden?\u201d </li> <li>Discipline to focus on simplicity is high leverage. </li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#fail-fast","title":"Fail Fast","text":"<ul> <li>Fail immediately and visibly.</li> <li>Doesn\u2019t necessarily mean crashing your programs for users.</li> <li>fail-fast to surface issues immediately. </li> <li>Failing fast is high leverage as it saves debugging time.</li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#relentlessly-automate","title":"Relentlessly Automate","text":"<ul> <li>Automating mechanics is good.</li> <li>Automating decision making - no.</li> <li>Hone your ability to respond and recover quickly.</li> <li>Leverage recovering quickly &gt; Leverage preventing failures.</li> <li>\u201cscript for success,\u201d practice failure scenarios, and work on our ability to recover quickly. </li> <li>Make batch process idempotent </li> <li>Make processes retryable, i.e., not leaving any global state. </li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#invest-in-your-teams-growth","title":"Invest in your team's Growth","text":"<ul> <li>Invest in onboarding.</li> <li>The higher you climb up the engineering ladder, the more your effectiveness will be measured not by your individual contributions but by your impact on the people around you.</li> </ul> <p>\"You\u2019re a staff engineer if you\u2019re making a whole team better than it would be otherwise. You\u2019re a principal engineer if you\u2019re making the whole company better than it would be otherwise. And you\u2019re distinguished if you\u2019re improving the industry.\u201d </p> <ul> <li>Focus primarily on making everyone around you succeed.</li> <li>Your career depends on your team's success.</li> <li>Make hiring everyone's responsibility. </li> <li>Shared ownership of code. </li> <li>Keep bus factor more than one. </li> <li>Shared ownership removes isolated silos of information.</li> <li>Build collective wisdom through post mortems.</li> <li>Invest in automated testing.</li> <li>Automated test cases lead to higher confidence when refactoring.</li> <li>Write test cases when the code is fresh in mind.</li> <li>Don\u2019t be dogmatic about 100% code coverage.</li> <li>Value of tests increases over time and cost to write goes down. </li> <li>Hire the best. </li> <li>Surround yourself with great advisors</li> </ul> <p>\u2600\ufe0f : \u201cLeverage is the lens through which effective engineers view their activities. \u201d \u2600\ufe0f</p>"},{"location":"Books/The%20Effective%20Engineer/#10-books-to-read","title":"10 Books to read","text":"<ul> <li>Peopleware Productive projects and Teams. Amazon. My Summary.</li> <li>Team Geek: A Software Developer\u2019s Guide to Working Well with Others. (Debugging Teams) Amazon. My Summary. </li> <li>High Output Management</li> <li>Getting Things Done: The Art of Stress-Free Productivity</li> <li>The 4-Hour Workweek: Escape 9-5, Live Anywhere, and Join the New Rich</li> <li>The 7 Habits of Highly Effective People: Powerful Lessons in Personal Change</li> <li>Conscious Business: How to Build Value Through Values</li> <li>Your Brain at Work</li> <li>Flow: The Psychology of Optimal Experience</li> <li>Succeed: How We Can Reach Our Goals</li> </ul>"},{"location":"Books/The%20Effective%20Engineer/#blogs","title":"Blogs:","text":"<p>Recommended Blogs To Follow:</p> <ul> <li>http://www.theeffectiveengineer.com/ - The Effective Engineer is my personal blog, where I write about engineering habits, productivity tips, leadership, and culture.</li> <li>http://www.kalzumeus.com/ - Patrick McKenzie runs his own software business and has written many excellent long-form articles on career advice, consulting, SEO, and software sales.</li> <li>http://katemats.com/ - Kate Matsudaira, who has worked at large companies like Microsoft and Amazon as well as at startups, shares advice about tech, leadership, and life on her blog.</li> <li>http://randsinrepose.com/ - Michael Lopp has worked for many years in leadership positions at Netscape, Apple, Palantir, and Pinterest, and writes about tech life and engineering management.</li> <li>http://softwareleadweekly.com/ - Oren Ellenbogen curates a high-quality weekly newsletter on engineering leadership and culture.</li> <li>http://calnewport.com/ - Cal Newport, an assistant professor of computer science at Georgetown, focuses on evidence-based advice for building a successful and fulfilling life.</li> <li>http://www.joelonsoftware.com/ - Joel Spolsky, the co-founder of Stack Exchange, provides all sorts of programming pearls of wisdom on his blog.</li> <li>http://martinfowler.com/ - Martin Fowler, author of the book Refactoring, writes about how to maximize the productivity of software teams and provides detailed write-ups of common programming patterns.</li> <li>http://pgbovine.net/ - Philip Guo, a computer science professor, has written extensively and openly about his graduate school and work experiences.</li> </ul>"},{"location":"Books/Underlines/","title":"Underlines","text":"<ul> <li>\"You just need to have the courage to eliminate everything that doesn't directly feed what you really want.\"</li> <li>Happiness is simply the absence of desire... Happiness is not about the achievement of pleasure (which is joy or satisfaction), but about the lack of desire. It arrives when you have no urge to feel differently. Happiness is the state you enter when you no longer want to change your state.</li> <li>People gravitate toward the standard you set, not the standard you request.</li> </ul>"},{"location":"Books/Your%20Money%20Ratios/","title":"Your Money Ratios","text":"<p>see your money and your life</p>"},{"location":"Books/Your%20Money%20or%20Your%20Life/","title":"Your Money or Your Life","text":"<p>Step 1: Make Peace with your Past Add up all the money you\u2019ve earned in your life, then add up your net worth today. How much have you managed to hold onto? How much did you spend? For most people, this yields an unpleasant surprise.. but it\u2019s okay, for there is no sense beating yourself up over past mistakes.</p> <p>Step 2: \u00a0Figure out your Real Earnings and Spending The idea here is that your real hourly wage is much lower than you think. You can figure it out as follows, and I\u2019ll even put in some plausible figures for a person with a 50,000 annual salary: Take your total monthly income after federal and state taxes: (3500) Then subtract all work-related expenses (commuting, clothes, restaurant lunches, housekeepers, daycare,de-stressing activities etc) ($1500) Divide this by your total work time (including commuting, dressing up, clothes cleaning, unwinding time, etc.) (248 hours)</p> <p>The net result is that you take home a lot less than you think, and spend a lot more time doing it. In the example above, the $50k earner ends up bringing home only $8.06 for each hour spent in activities directly related to the job. Thus, when you decide to buy yourself an 8 dollar treat at Starbucks or at the pub, you\u2019ve really just burned off an entire hour of \u201clife energy\u201d which you\u2019ll never get back \u2013 you have to add that hour to the end of your work career to achieve financial independence.</p> <p>Tracking your spending is the easy part \u2013 the book recommends you use a notebook to handle everything, whereas I just do all of my spending by credit card, allowing it to be tracked automatically. The key, however, is you should know\u00a0exactly\u00a0what you buy each day, and why you decide to buy it. No more unconscious impulse shopping.</p> <p>3: Create Monthly Reports for Yourself</p> <p>Keep a table of all income and all spending for each month, break it into categories, and convert the figures into \u201chours of life energy spent\u201d. Restaurant meals: 20 hours., etc. I find that the \u201cMint\u201d financial tool does an acceptable job of this for me, but the book recommends you do it in more detail.</p> <p>4: Three Questions that will Supposedly Transform your Life: For each of the categories above, ask yourself: -   Did I receive fulfillment in proportion to the hours of life energy spent? -   Is this expenditure in alignment with my goals and life purpose? -   How might this expenditure change if I didn\u2019t have to work for a living? (more, less, same)</p> <p>5: Keep a prominent (i.e. right on your kitchen wall) graph of income and expenses You keep doing this for multiple months which will grow into multiple years.\u00a0The authors report that most people start to see their income grow even as their expenses shrink, since they are now learning to spend more consciously. Although I don\u2019t have anything on my kitchen wall, we do maintain a history of spreadsheet versions and graphs of savings that dates back several years. But if you are a beginner who still wrangles with optional luxury purchases while still in debt, the kitchen wall is a good idea.</p> <p>6: Learn to Value your Life Energy by Minimizing Spending This is the meat of anyone\u2019s financial independence \u2013 learning to spend your money efficiently on the things you do get true fulfillment from, and not spend it all on the things you don\u2019t. \u00a0The book presents 101 tips, most of which have been covered here on this blog at various times.</p> <p>7: Maximize your Earnings Adopt a positive attitude about your work and appreciate the earnings as a tool which gets you to financial independence.. rather than feeling like a victim of outside forces like the economy or a recession. Seek to earn more, and don\u2019t be limited to work only in your current field \u2013 after all, you\u2019ll be retiring soon anyway, meaning every activity will soon be open to you whether paid or unpaid.</p> <p>8: Watch for the Crossover Point This is when your passive income from investments equals your expenses. When you reach that point \u2013 DingDing! \u2013 you are Financially Independent. However, the authors define this as \u201cMonthly Income = Capital x Current long-term interest rate/12 months\u201d, since they like government bonds as their retirement income vehicle, which currently pay approximately zero after adjusting for inflation. But Mustachians of course have other options, discussed below.</p> <p>9: Managing your Money \u201cBecome knowledgeable and invest your capital in such a way as to provide an absolutely safe income sufficient to meet your basic needs for life\u201d</p> <p>Here\u2019s where one of the most significant differences pops up between YMOYL and MMM (and other modern takes on financial independence). In the early 1980s, you could buy\u00a030-year government bonds\u00a0with a nominal yield of over 12%. Even in the surrounding time periods, yields were well over 7%. The YM authors liked the guaranteed return and decided to use these bonds as a complete income source*.</p> <p>Due to our continued hangover from the financial crisis, the latest figure for the 30-year bonds is about 2.9%. While it is still possible to retire on bonds, I consider an over-50% reduction in investment returns in exchange for \u201csafety\u201d to be too high a price to pay.\u00a0Safety is just an expensive illusion\u00a0anyway. So instead of bonds, we focus here on stocks,\u00a0dividends,owning rental real estate\u00a0(or its passive cousin\u00a0REITs), and even a bit of wacky new higher risk/return stuff like\u00a0peer-to-peer lending. And on top of that, I don\u2019t consider \u201cretirement\u201d to mean \u201cnever accepting money for things you do\u201d, so I allow you to do fun things that happen to generate money in retirement as well.</p> <p>Your Money or Your Life is a wise book, and the authors were clearly motivated by what they saw was a pointless death march of society. Workworkwork, Buybuybuy, TrashDestroyWaste, Die. Even 20 years ago, when the first clunky SUVs were coming to market and trailblazing a path to widespread stupidity, this pattern was already obvious. And Joe and Vicki were wise to it, trying to guide society away from its wasteful ways and vividly aware that our consumption is an ongoing trainwreck of environmental destruction.</p> <p>The bad news is that we went through some pretty shitty decades since then, when measured by the spread of the very consumer disease the book was fighting against. Cars turned into personal trucks, commutes grew, suburbs sprawled, and China joined the party, building a communist copy of the Great American Smokestack, flooding their own country with asphalt and ours with cheap manufactured goods. Americans kept working more so they could borrow more and buy more, we grew much fatter and less happy, and generally continue to live our lives in the most blind and inefficient way possible on average.</p> <p>The good news is, the Internet happened. Of course, it spawned an acceleration of technological progress, giving us things like remote working and energy-efficient products. But technology can\u2019t save the world by itself \u2013 in the wrong hands, it just allows us to consume more efficiently, which means consuming more. It\u2019s a good tool, but it\u2019s not enough.</p> <p>The good news comes from the free exchange of ideas. Only now can the ideas of the non-wealthy majority compete equally with the billion-dollar budgets of crusty old companies seeking to prolong over-consumption. Nowadays, even an untrained individual can sit on the couch and type some shit into the computer, and it can reach a wider audience than a successful book might have in the past. So imagine what a big group of people could accomplish, some of them with influence over companies and governments, if they all started grooving on the right message.</p>"},{"location":"How/How%20does%20VISA%20make%20money/","title":"How does VISA make money","text":""},{"location":"How/How%20does%20VISA%20make%20money/#how-does-visa-make-money","title":"How does Visa make money","text":"<ol> <li> <p>The cardholder pays a merchant $100 to buy a product.</p> </li> <li> <p>The merchant benefits from the use of the credit card with higher sales volume, and needs to compensate the issuer and the card network for providing the payment service. The acquiring bank sets a fee with the merchant, called the \u201c\ud835\udc26\ud835\udc1e\ud835\udc2b\ud835\udc1c\ud835\udc21\ud835\udc1a\ud835\udc27\ud835\udc2d \ud835\udc1d\ud835\udc22\ud835\udc2c\ud835\udc1c\ud835\udc28\ud835\udc2e\ud835\udc27\ud835\udc2d \ud835\udc1f\ud835\udc1e\ud835\udc1e.\u201d</p> </li> </ol> <p>3 - 4. The acquiring bank keeps $0.25 as the \ud835\udc1a\ud835\udc1c\ud835\udc2a\ud835\udc2e\ud835\udc22\ud835\udc2b\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc26\ud835\udc1a\ud835\udc2b\ud835\udc24\ud835\udc2e\ud835\udc29, and $1.75 is paid to the issuing bank as the \ud835\udc22\ud835\udc27\ud835\udc2d\ud835\udc1e\ud835\udc2b\ud835\udc1c\ud835\udc21\ud835\udc1a\ud835\udc27\ud835\udc20\ud835\udc1e \ud835\udc1f\ud835\udc1e\ud835\udc1e. The merchant discount fee should cover the interchange fee.</p> <p>The interchange fee is set by the card network because it is less efficient for each issuing bank to negotiate fees with each merchant.</p> <ol> <li> <p>The card network sets up the \ud835\udc27\ud835\udc1e\ud835\udc2d\ud835\udc30\ud835\udc28\ud835\udc2b\ud835\udc24 \ud835\udc1a\ud835\udc2c\ud835\udc2c\ud835\udc1e\ud835\udc2c\ud835\udc2c\ud835\udc26\ud835\udc1e\ud835\udc27\ud835\udc2d\ud835\udc2c \ud835\udc1a\ud835\udc27\ud835\udc1d \ud835\udc1f\ud835\udc1e\ud835\udc1e\ud835\udc2c with each bank, which pays the card network for its services every month. For example, VISA charges a 0.11% assessment, plus a $0.0195 usage fee, for every swipe.</p> </li> <li> <p>The cardholder pays the issuing bank for its services.</p> </li> </ol> <p>Why should the issuing bank be compensated?</p> <ul> <li>The issuer pays the merchant even if the cardholder fails to pay the issuer.</li> <li>The issuer pays the merchant before the cardholder pays the issuer.</li> <li>The issuer has other operating costs, including managing customer accounts, providing statements, fraud detection, risk management, clearing &amp; settlement, etc.</li> </ul>"},{"location":"Self-Help/Food%20For%20Thought/","title":"Food For Thought","text":"<ul> <li>we often lead from our \"aspirational self\" and not the real self.</li> </ul>"},{"location":"Self-Help/Game%20Theory%20of%20Trust/","title":"Game Theory of Trust","text":"<ul> <li>https://ncase.me/trust/?ftag=CAD-03-10abj4f</li> </ul>"},{"location":"Software%20Engineering/12f-app/","title":"12f app","text":"<ol> <li>Codebase: One codebase tracked in revision control, many deploys</li> <li>Dependencies Explicitly declare and isolate dependencies</li> <li>Config Store config in the environment</li> <li>Backing services Treat backing services as attached resources</li> <li>Build, release, run Strictly separate build and run stages</li> <li>Processes Execute the app as one or more stateless processes</li> <li>Port binding Export services via port binding</li> <li>Concurrency Scale out via the process model</li> <li>Disposability Maximize robustness with fast startup and graceful shutdown</li> <li>Dev/prod parity Keep development, staging, and production as similar as possible</li> <li>Logs Treat logs as event streams</li> <li>Admin processes Run admin/management tasks as one-off processes</li> </ol>"},{"location":"Software%20Engineering/ArchPatterns/","title":"ArchPatterns","text":""},{"location":"Software%20Engineering/ArchPatterns/#monolithic-architecture","title":"Monolithic architecture","text":"<p>The entire application is built as a single, unified codebase.  Pros: For small teams or projects, monoliths provide simplicity, fast development, and easy deployment. Cons:  1. Scalability Bottlenecks: The entire application is scaled as a single unit in a monolith. If only one part of the application experiences high demand (for example, a reporting module), the entire application must scale, wasting resources on less demanding components. 2. Maintenance Issues: As the codebase grows, dependencies between different parts of the application increase and each change has a larger impact radius. 3. Deployment Complexity: In a monolithic system, a small change in one module requires redeploying the entire application. 4. Limited Technology Choices: All parts of a monolith must typically use the same technology stack. We cannot use specilized library written python for targeted feature. 5. Resiliency Challenge:  A failure in one part of a monolith can bring down the entire application.</p>"},{"location":"Software%20Engineering/Docker/","title":"Docker","text":""},{"location":"Software%20Engineering/Docker/#docker-commands","title":"Docker Commands","text":"<ul> <li><code>docker logs &lt;container_id&gt;</code></li> <li><code>docker stats &lt;container_id&gt;</code>  : If you just need to keep an eye on the metrics of your container to work out what\u2019s gone wrong, docker stats can help: it\u2019ll give you a live stream of resource usage, so you can see just how much memory you\u2019ve leaked so far.</li> <li><code>docker cp &lt;container_id&gt; : /path/to/useful/file/local-path</code> Often just getting hold of more log files is enough to sort you out. If you already know what you want, docker cp has your back: copy any file from any container back out onto your local machine, so you can examine it in depth (especially useful analysing heap dumps)._</li> <li><code>docker exec -it &lt;container_id&gt; /bin/bash</code>  : Next up, if you can run the container (if it\u2019s crashed, you can restart it with docker start ), shell in directly and start digging around for further details by hand. <li><code>docker commit &lt;container_id&gt;</code> my-broken-container &amp;&amp; docker run -it my-broken-container /bin/bash</li>"},{"location":"Software%20Engineering/MicroServices/","title":"MicroServices","text":""},{"location":"Software%20Engineering/MicroServices/#microservices","title":"MicroServices","text":"<ul> <li>breaks the monolithic app into smaller components</li> <li>independently deployable</li> <li>scalable</li> <li>testable</li> </ul>"},{"location":"Software%20Engineering/MicroServices/#challenges","title":"Challenges","text":"<ul> <li>Data Consistency and Eventual Consistency: In a microservices architecture, data is often distributed across multiple nodes, which can be located in different data centers or even different geographic regions. At any given point in time, there can be discrepancies in the state of data between various nodes. This phenomenon is known as eventual consistency.</li> <li>Security: Microservices architecture introduces a larger attack surface for malicious actors compared to monolithic systems. It\u2019s crucial to establish appropriate security mechanisms while building microservices. <ul> <li>Design patterns such as the API Gateway pattern can help.</li> </ul> </li> <li>Scalability and Database Performance: Microservices are known for their scalability. However, while it is relatively easy to scale the application layer by adding more instances, databases can become performance bottlenecks if not designed for scalability. <ul> <li>Patterns such as Database per Service and CQRS help solve this challenge.</li> </ul> </li> </ul>"},{"location":"Software%20Engineering/NFR/","title":"NFR","text":""},{"location":"Software%20Engineering/NFR/#scalability","title":"Scalability","text":"<ul> <li>an ability of the system to respond to the increased traffic w/o degrading the performance</li> </ul>"},{"location":"Software%20Engineering/NFR/#scalability-bottlenecks","title":"Scalability bottlenecks","text":"<ul> <li>centralized components</li> <li>high latency components</li> <li>tight coupling</li> </ul>"},{"location":"Software%20Engineering/NFR/#solutions","title":"solutions","text":"<ul> <li>load balancing</li> <li>caching</li> <li>event-driven</li> <li>sharding</li> </ul>"},{"location":"Software%20Engineering/Popular%20OS%20Projects/","title":"Popular OS Projects","text":"<p>Google - Kubernetes - TensorFlow - Go - Angular</p> <p>Meta - React - PyTorch - GraphQL - Cassandra</p> <p>Microsoft - VSCode - TypeScript - Playwright</p> <p>Netflix - Chaos Monkey - Hystrix - Zuul</p> <p>LinkedIn - Kafka - Samza - Pinot</p> <p>RedHat - Ansible - OpenShift - Ceph Storage</p>"},{"location":"Software%20Engineering/Setting%20Up%20Mac%20for%20Coding/","title":"Setting Up Mac for Coding","text":""},{"location":"Software%20Engineering/Setting%20Up%20Mac%20for%20Coding/#mac-setup","title":"Mac Setup","text":"<ol> <li>Check you're admin</li> <li>Spotlight &gt;&gt; Users &amp; Groups &gt;&gt; Password = Check Allow user to admin this computer</li> <li>Run following on Terminal <code>sudo plutil -p /var/db/dslocal/nodes/Default/users/root.plist | grep -A 2 passwd</code></li> <li> <p>Below output means root user is not enabled.</p> <pre><code> \"passwd\" =&gt; [\n    0 =&gt; \"*\"\n]\n</code></pre> </li> <li> <p>Below output means root user is enabled.</p> <p><code>sh    \"passwd\" =&gt; [     0 =&gt; \"********\" ]</code></p> </li> <li> <p>To enable root user, Spotlight &gt;&gt; Directory Utility = Click on the lock at the bottom to unlock it. Edit menu &gt;&gt; Enable Root User</p> </li> <li> <p>Customize  Mac</p> </li> <li> <p>Finder         - Show Finder path in Status bar: View \u00bb Show Path Bar         - Drag and drop your favourite folders into the left-side Favorites bar e.g. Macintosh HD, Repos.         - Show hidden files and folders using Terminal commands:</p> <pre><code>```sh\ndefaults write\u00a0com.apple.finder\u00a0AppleShowAllFiles YES\nKillall Finder\n// Then, restart the Finder by holding down Option+Control and clicking the Finder icon in the Dock, then choose Relaunch\n```\n</code></pre> </li> <li> <p>Trackpad</p> <ul> <li>Spotlight &gt;&gt; Trackpad &gt;&gt; Point &amp; Click = Check Tap to Click</li> <li>Spotlight &gt;&gt; Trackpad &gt;&gt; Point &amp; Click = Un-check Force Click and Haptic Feedback</li> <li>Spotlight &gt;&gt; Trackpad &gt;&gt; Point &amp; Click = Increase Tracking Speed</li> </ul> </li> <li> <p>Keyboard</p> <ul> <li>Spotlight &gt;&gt; Keyboard &gt;&gt; Keyboard = Check Use F1,F2  keys as standard keys</li> <li>Spotlight &gt;&gt; Keyboard &gt;&gt; Shortcuts = Double click Show Desktop and hit Cmd+D    </li> </ul> </li> <li> <p>Desktop</p> <ul> <li>Spotlight &gt;&gt; Desktop &amp; Screensavers &gt;&gt; Screen Saver = Check 'Show with clock'</li> <li>Spotlight &gt;&gt; Desktop &amp; Screensavers &gt;&gt; Screen Saver =&gt; Hot Corners<ul> <li> <p>Left Bottom = Desktop</p> </li> <li> <p>Right Bottom = Screen Saver</p> </li> </ul> </li> </ul> </li> <li> <p>Locking         - Spotlight &gt;&gt; Keychain Access &gt;&gt; Preferences = Check 'Show keychain status in menu bar'.</p> </li> <li> <p>Screen Saver         - From Finder &gt;&gt; Go To &gt;&gt; <code>/System/Library/Frameworks/ScreenSaver.framework/Versions/A/Resources/</code> (Sierra)         - Drag and Drop ScreenSaveEngine app on Dock.         - High Sierra = <code>/System/Library/CoreServices/</code></p> <ol> <li> <p>Development Tools &amp; Settings</p> </li> <li> <p>VS Code</p> </li> <li>iTerm2</li> <li>Sublime</li> <li>SnagIt</li> <li>Spectacle</li> <li>Date-O</li> </ol> </li> </ol>"},{"location":"Software%20Engineering/Setting%20Up%20Mac%20for%20Coding/#mac-tips","title":"Mac Tips","text":"<ol> <li> <p>Start-up Programs</p> <ul> <li>Spotlight &gt;&gt; Users &amp; Groups &gt;&gt; Login Items = Add apps </li> </ul> </li> <li> <p>Productivity Tips</p> Command Purpose CMD+Ctrl+F Full Screen Spotlight Find app, use as calculator, dictionary File delete Backspace delete Back Delete del Forward delete fn del Capture Screen CMD+SHIFT+4 Move Up/Down the Folders CMD + Up/Down CMD Full CMD Full </li> </ol>"},{"location":"Software%20Engineering/Setting%20Up%20the%20Terminal/","title":"Setting Up the Terminal","text":""},{"location":"Software%20Engineering/Setting%20Up%20the%20Terminal/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>iTerm2</li> <li>Visual Studio Code</li> <li> <p>brew : <code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"</code></p> </li> <li> <p>Install \"Oh My Zsh\"</p> </li> </ul> <pre><code>sh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"\n</code></pre> <ol> <li>Install theme Powerlevel10k</li> </ol> <pre><code>git clone https://github.com/romkatv/powerlevel10k.git $ZSH_CUSTOM/themes/powerlevel10k\ncode ~/.zshrc\nZSH_THEME=\"powerlevel10k/powerlevel10k\"\n</code></pre> <p>Then save the <code>zshrc</code> file, quit the iTerm2, and re-open it. You will see the Powerlevel10k configuration wizard.</p> <p>You can run the wizard later with the below command on iTerm.</p> <p><pre><code>pk10 configure\n</code></pre> </p> <ol> <li>Syntax highlighting.</li> </ol> <pre><code>brew install zsh-syntax-highlighting\nsource /usr/local/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh\n</code></pre>"}]}